{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98426f68",
   "metadata": {},
   "source": [
    "\n",
    "# Calibración de la Cámara y Guardado de Parámetros con Visualización Ajustada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e6dd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error total de reproyección: 0.18229606217871813\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "\n",
    "# Definir el tamaño del tablero de ajedrez (por ejemplo, 6x6 esquinas internas)\n",
    "CHECKERBOARD = (6,6)\n",
    "\n",
    "# Criterios de terminación\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Preparar puntos objeto\n",
    "objp = np.zeros((CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1,2)\n",
    "\n",
    "# Arrays para almacenar puntos objeto y puntos imagen de todas las imágenes\n",
    "objpoints = [] # puntos 3d en el espacio real (del mundo)\n",
    "imgpoints = [] # puntos 2d en el plano de la imagen\n",
    "\n",
    "# Obtener lista de imágenes\n",
    "images = glob.glob('*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Encontrar esquinas del tablero\n",
    "    ret, corners = cv.findChessboardCorners(gray, CHECKERBOARD, None)\n",
    "\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        # Dibujar y mostrar las esquinas\n",
    "        cv.drawChessboardCorners(img, CHECKERBOARD, corners2, ret)\n",
    "        \n",
    "        # Redimensionar la imagen para que se muestre en una ventana más pequeña\n",
    "        resize_width = 640\n",
    "        resize_height = int(img.shape[0] * (resize_width / img.shape[1]))\n",
    "        resized_img = cv.resize(img, (resize_width, resize_height))\n",
    "\n",
    "        cv.imshow('Esquinas del Tablero', resized_img)\n",
    "        cv.waitKey(500)\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "# Calibración\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "# Guardar los parámetros de calibración y puntos clave para evitar reprocesar las imágenes\n",
    "np.savez('calibration_params.npz', mtx=mtx, dist=dist, rvecs=rvecs, tvecs=tvecs, objpoints=objpoints, imgpoints=imgpoints)\n",
    "\n",
    "# Calcular el error de reproyección\n",
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2)/len(imgpoints2)\n",
    "    mean_error += error\n",
    "\n",
    "print(\"Error total de reproyección: {}\".format(mean_error/len(objpoints)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a316f2",
   "metadata": {},
   "source": [
    "# Uso de los Parámetros Guardados, Corrección de Imagen y Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8075b15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error total: 0.18229606217871813\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Cargar los parámetros de calibración\n",
    "with np.load('calibration_params.npz') as data:\n",
    "    mtx, dist, rvecs, tvecs = [data[i] for i in ('mtx', 'dist', 'rvecs', 'tvecs')]\n",
    "    objpoints, imgpoints = [data[i] for i in ('objpoints', 'imgpoints')]\n",
    "\n",
    "# Leer la imagen\n",
    "img = cv.imread('calibration_images/prueba2.jpg')\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "# Obtener la matriz nueva de la cámara y la región de interés\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "# Inicializar el mapa de corrección\n",
    "mapx, mapy = cv.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w,h), 5)\n",
    "\n",
    "# Remapear la imagen\n",
    "dst = cv.remap(img, mapx, mapy, cv.INTER_LINEAR)\n",
    "\n",
    "# Recortar la imagen según la región de interés\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "\n",
    "# Guardar la imagen corregida\n",
    "cv.imwrite('calibration_images/calibresult.png', dst)\n",
    "\n",
    "# Mostrar la imagen original y la imagen de-distorsionada en ventanas más pequeñas\n",
    "cv.namedWindow('Imagen Original', cv.WINDOW_NORMAL)\n",
    "cv.resizeWindow('Imagen Original', 600, 400)  # Cambia el tamaño a 600x400 píxeles\n",
    "cv.imshow('Imagen Original', img)\n",
    "\n",
    "cv.namedWindow('Imagen De-Distorsionada', cv.WINDOW_NORMAL)\n",
    "cv.resizeWindow('Imagen De-Distorsionada', 800, 500)  # Cambia el tamaño a 600x400 píxeles\n",
    "cv.imshow('Imagen De-Distorsionada', dst)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "# Calcular el error de proyección\n",
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2) / len(imgpoints2)\n",
    "    mean_error += error\n",
    "\n",
    "print(\"Error total: {}\".format(mean_error / len(objpoints)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b3033e",
   "metadata": {},
   "source": [
    "# creacion del aruco y guardado en un archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d6c1cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Parámetros de los marcadores ArUco\n",
    "aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_6X6_50)\n",
    "marker_id = 0  # ID del marcador que deseas generar\n",
    "marker_size = 700  # Tamaño del marcador en píxeles\n",
    "\n",
    "# Generar el marcador ArUco\n",
    "marker_img = np.zeros((marker_size, marker_size), dtype=np.uint8)\n",
    "marker_img = cv2.aruco.drawMarker(aruco_dict, marker_id, marker_size, marker_img, 1)\n",
    "\n",
    "# Guardar el marcador como imagen\n",
    "cv2.imwrite('Aruco/aruco_marker4.png', marker_img)\n",
    "\n",
    "# Mostrar el marcador en una ventana\n",
    "cv2.imshow('ArUco Marker', marker_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d529cd91",
   "metadata": {},
   "source": [
    "# Implementacion de detector de intrusos en un área especifica usando aruco y detector de personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3061da2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Francisco\\anaconda3\\envs\\Examen\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2.aruco as aruco\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import winsound\n",
    "\n",
    "# Factor de escala para aumentar el tamaño de la ventana\n",
    "scale_factor = 3  # Aumenta este valor para hacer la ventana más grande\n",
    "\n",
    "# Cargar el modelo MobileNet SSD v2 pre-entrenado de TensorFlow Hub\n",
    "MODEL_PATH = \"ssd_mobilenet_v2_model\" # Asegúrate de que esta ruta sea correcta\n",
    "detector = tf.saved_model.load(MODEL_PATH)\n",
    "\n",
    "# Cargar los parámetros de la cámara desde el archivo de calibración\n",
    "calibration_data = np.load('calibration_params.npz')\n",
    "camera_matrix = calibration_data['mtx']\n",
    "dist_coeffs = calibration_data['dist']\n",
    "\n",
    "# Configuración inicial de ArUco\n",
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_50)  # ArUco de 6x6\n",
    "aruco_params = aruco.DetectorParameters_create()\n",
    "\n",
    "# Inicializar la cámara\n",
    "cap = cv2.VideoCapture(0)   # 0 para la cámara web predeterminada\n",
    "\n",
    "# Factor de desplazamiento para ampliar el área alrededor del marcador\n",
    "expand_by = 100\n",
    "\n",
    "# Variable para controlar cada cuántos cuadros procesar\n",
    "process_every_n_frames = 5\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # Solo procesar 1 de cada process_every_n_frames cuadros\n",
    "    if frame_count % process_every_n_frames != 0:\n",
    "        continue\n",
    "\n",
    "    # Corregir la distorsión de la imagen\n",
    "    h, w = frame.shape[:2]\n",
    "    new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, dist_coeffs, (w, h), 1, (w, h))\n",
    "    undistorted_frame = cv2.undistort(frame, camera_matrix, dist_coeffs, None, new_camera_matrix)\n",
    "\n",
    "    # Recortar el área útil\n",
    "    x, y, w, h = roi\n",
    "    undistorted_frame = undistorted_frame[y:y+h, x:x+w]\n",
    "\n",
    "    # Detección de marcadores ArUco en la imagen corregida\n",
    "    corners, ids, _ = aruco.detectMarkers(undistorted_frame, aruco_dict, parameters=aruco_params)\n",
    "    \n",
    "    prohibited_area = None\n",
    "    \n",
    "    if ids is not None:\n",
    "        for i in range(len(ids)):\n",
    "            c = corners[i][0]\n",
    "            \n",
    "            # Expande cada esquina del área prohibida alrededor del marcador\n",
    "            top_left = [c[0][0] - expand_by, c[0][1] - expand_by]\n",
    "            top_right = [c[1][0] + expand_by, c[1][1] - expand_by]\n",
    "            bottom_right = [c[2][0] + expand_by, c[2][1] + expand_by]\n",
    "            bottom_left = [c[3][0] - expand_by, c[3][1] + expand_by]\n",
    "            \n",
    "            # Crear el área prohibida ampliada alrededor del marcador en el suelo\n",
    "            prohibited_area = np.array([top_left, top_right, bottom_right, bottom_left], dtype=np.int32)\n",
    "            \n",
    "            # Dibujar el área prohibida en la imagen\n",
    "            cv2.polylines(undistorted_frame, [prohibited_area], isClosed=True, color=(0, 255, 0), thickness=3)\n",
    "\n",
    "    # Preprocesar la imagen para el modelo de detección de personas\n",
    "    input_tensor = tf.convert_to_tensor(undistorted_frame)\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # Realizar la detección\n",
    "    detections = detector(input_tensor)\n",
    "\n",
    "    # Procesar las detecciones\n",
    "    boxes = detections['detection_boxes'][0].numpy()\n",
    "    classes = detections['detection_classes'][0].numpy().astype(np.int32)\n",
    "    scores = detections['detection_scores'][0].numpy()\n",
    "\n",
    "    # Dibujar las detecciones en el frame\n",
    "    height, width, _ = undistorted_frame.shape\n",
    "    intrusion_detected = False\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "        if scores[i] > 0.5 and classes[i] == 1:  # class 1 es 'person'\n",
    "            ymin, xmin, ymax, xmax = boxes[i]\n",
    "            xmin = int(xmin * width)\n",
    "            xmax = int(xmax * width)\n",
    "            ymin = int(ymin * height)\n",
    "            ymax = int(ymax * height)\n",
    "\n",
    "            # Dibujar la caja de detección de persona\n",
    "            cv2.rectangle(undistorted_frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "            cv2.putText(undistorted_frame, f'Person: {scores[i]:.2f}', (xmin, ymin - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            # Verificar si la persona está dentro del área prohibida\n",
    "            if prohibited_area is not None:\n",
    "                for (px, py) in [(xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)]:\n",
    "                    if cv2.pointPolygonTest(prohibited_area, (px, py), False) >= 0:\n",
    "                        intrusion_detected = True\n",
    "                        break\n",
    "\n",
    "    # Si se detecta una intrusión, mostrar alerta y activar sonido\n",
    "    if intrusion_detected:\n",
    "        cv2.putText(undistorted_frame, 'INTRUSION DETECTED', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        winsound.Beep(1000, 500)\n",
    "\n",
    "    # Redimensionar el frame para mostrar una ventana más grande\n",
    "    display_frame = cv2.resize(undistorted_frame, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Mostrar el video en tiempo real con el área prohibida y detecciones de personas\n",
    "    cv2.imshow('Intrusion Detection', display_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
