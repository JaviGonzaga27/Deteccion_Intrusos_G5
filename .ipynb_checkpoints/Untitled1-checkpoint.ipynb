{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98426f68",
   "metadata": {},
   "source": [
    "\n",
    "# Calibración de la Cámara y Guardado de Parámetros con Visualización Ajustada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "\n",
    "# Definir el tamaño del tablero de ajedrez (por ejemplo, 6x6 esquinas internas)\n",
    "CHECKERBOARD = (6,6)\n",
    "\n",
    "# Criterios de terminación\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Preparar puntos objeto\n",
    "objp = np.zeros((CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1,2)\n",
    "\n",
    "# Arrays para almacenar puntos objeto y puntos imagen de todas las imágenes\n",
    "objpoints = [] # puntos 3d en el espacio real (del mundo)\n",
    "imgpoints = [] # puntos 2d en el plano de la imagen\n",
    "\n",
    "# Obtener lista de imágenes\n",
    "images = glob.glob('*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Encontrar esquinas del tablero\n",
    "    ret, corners = cv.findChessboardCorners(gray, CHECKERBOARD, None)\n",
    "\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        # Dibujar y mostrar las esquinas\n",
    "        cv.drawChessboardCorners(img, CHECKERBOARD, corners2, ret)\n",
    "        cv.imshow('Esquinas del Tablero', img)\n",
    "        cv.waitKey(500)\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "# Calibración\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "# Guardar los parámetros de calibración y puntos clave para evitar reprocesar las imágenes\n",
    "np.savez('calibration_params.npz', mtx=mtx, dist=dist, rvecs=rvecs, tvecs=tvecs, objpoints=objpoints, imgpoints=imgpoints)\n",
    "\n",
    "# Calcular el error de reproyección\n",
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2)/len(imgpoints2)\n",
    "    mean_error += error\n",
    "\n",
    "print(\"Error total de reproyección: {}\".format(mean_error/len(objpoints)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8075b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Cargar los parámetros de calibración\n",
    "with np.load('calibration_params.npz') as data:\n",
    "    mtx, dist, rvecs, tvecs = [data[i] for i in ('mtx', 'dist', 'rvecs', 'tvecs')]\n",
    "    objpoints, imgpoints = [data[i] for i in ('objpoints', 'imgpoints')]\n",
    "\n",
    "# Leer la imagen\n",
    "img = cv.imread('20240824_235719.jpg')\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "# Obtener la matriz nueva de la cámara y la región de interés\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "# Inicializar el mapa de corrección\n",
    "mapx, mapy = cv.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w,h), 5)\n",
    "\n",
    "# Remapear la imagen\n",
    "dst = cv.remap(img, mapx, mapy, cv.INTER_LINEAR)\n",
    "\n",
    "# Recortar la imagen según la región de interés\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "\n",
    "# Guardar la imagen corregida\n",
    "cv.imwrite('calibresult.png', dst)\n",
    "\n",
    "# Mostrar la imagen original y la imagen de-distorsionada en ventanas más pequeñas\n",
    "cv.namedWindow('Imagen Original', cv.WINDOW_NORMAL)\n",
    "cv.resizeWindow('Imagen Original', 600, 400)  # Cambia el tamaño a 600x400 píxeles\n",
    "cv.imshow('Imagen Original', img)\n",
    "\n",
    "cv.namedWindow('Imagen De-Distorsionada', cv.WINDOW_NORMAL)\n",
    "cv.resizeWindow('Imagen De-Distorsionada', 800, 500)  # Cambia el tamaño a 600x400 píxeles\n",
    "cv.imshow('Imagen De-Distorsionada', dst)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "# Calcular el error de proyección\n",
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2) / len(imgpoints2)\n",
    "    mean_error += error\n",
    "\n",
    "print(\"Error total: {}\".format(mean_error / len(objpoints)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6c1cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Parámetros de los marcadores ArUco\n",
    "aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_6X6_50)\n",
    "marker_id = 4  # ID del marcador que deseas generar\n",
    "marker_size = 700  # Tamaño del marcador en píxeles\n",
    "\n",
    "# Generar el marcador ArUco\n",
    "marker_img = np.zeros((marker_size, marker_size), dtype=np.uint8)\n",
    "marker_img = cv2.aruco.drawMarker(aruco_dict, marker_id, marker_size, marker_img, 1)\n",
    "\n",
    "# Guardar el marcador como imagen\n",
    "cv2.imwrite('aruco_marker4.png', marker_img)\n",
    "\n",
    "# Mostrar el marcador en una ventana\n",
    "cv2.imshow('ArUco Marker', marker_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43265af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2.aruco as aruco\n",
    "import winsound\n",
    "\n",
    "# Cargar los parámetros de la cámara desde el archivo de calibración\n",
    "calibration_data = np.load('calibration_params.npz')\n",
    "camera_matrix = calibration_data['mtx']\n",
    "dist_coeffs = calibration_data['dist']\n",
    "\n",
    "# Configuración inicial de ArUco\n",
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_50)  # ArUco de 6x6\n",
    "aruco_params = aruco.DetectorParameters_create()\n",
    "\n",
    "# Captura de video desde la cámara (puede ser DroidCam o cualquier otra fuente)\n",
    "cap = cv2.VideoCapture('http://192.168.3.26:4747/video')\n",
    "\n",
    "# Inicializar sustractor de fondo\n",
    "backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Factor de desplazamiento para ampliar el área alrededor del marcador (ajústalo según necesites)\n",
    "expand_by = 100  # Puedes ajustar este valor\n",
    "\n",
    "intrusion_detected = False\n",
    "alarm_active = False\n",
    "\n",
    "# Variable para controlar cada cuántos cuadros procesar\n",
    "process_every_n_frames = 5\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # Solo procesar 1 de cada `process_every_n_frames` cuadros\n",
    "    if frame_count % process_every_n_frames != 0:\n",
    "        continue\n",
    "\n",
    "    # Corregir la distorsión de la imagen\n",
    "    h, w = frame.shape[:2]\n",
    "    new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, dist_coeffs, (w, h), 1, (w, h))\n",
    "    undistorted_frame = cv2.undistort(frame, camera_matrix, dist_coeffs, None, new_camera_matrix)\n",
    "\n",
    "    # Recortar el área útil\n",
    "    x, y, w, h = roi\n",
    "    undistorted_frame = undistorted_frame[y:y+h, x:x+w]\n",
    "\n",
    "    # Detección de marcadores ArUco en la imagen corregida\n",
    "    corners, ids, _ = aruco.detectMarkers(undistorted_frame, aruco_dict, parameters=aruco_params)\n",
    "    \n",
    "    if ids is not None:\n",
    "        for i in range(len(ids)):\n",
    "            c = corners[i][0]\n",
    "            \n",
    "            # Expande cada esquina del área prohibida alrededor del marcador\n",
    "            top_left = [c[0][0] - expand_by, c[0][1] - expand_by]\n",
    "            top_right = [c[1][0] + expand_by, c[1][1] - expand_by]\n",
    "            bottom_right = [c[2][0] + expand_by, c[2][1] + expand_by]\n",
    "            bottom_left = [c[3][0] - expand_by, c[3][1] + expand_by]\n",
    "            \n",
    "            # Crear el área prohibida ampliada alrededor del marcador en el suelo\n",
    "            prohibited_area = np.array([\n",
    "                top_left,\n",
    "                top_right,\n",
    "                bottom_right,\n",
    "                bottom_left\n",
    "            ], dtype=np.int32)\n",
    "            \n",
    "            # Dibujar el área prohibida en la imagen (color verde para mayor visibilidad)\n",
    "            cv2.polylines(undistorted_frame, [prohibited_area], isClosed=True, color=(0, 255, 0), thickness=3)\n",
    "\n",
    "            # Detección de movimiento e intrusión\n",
    "            fg_mask = backSub.apply(undistorted_frame)\n",
    "            contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            for cnt in contours:\n",
    "                if cv2.contourArea(cnt) > 500:  # Filtrar pequeñas detecciones\n",
    "                    x, y, w, h = cv2.boundingRect(cnt)\n",
    "                    \n",
    "                    # Verificar si el intruso está dentro del área prohibida\n",
    "                    for point in [(x, y), (x+w, y), (x+w, y+h), (x, y+h)]:\n",
    "                        if cv2.pointPolygonTest(prohibited_area, point, False) >= 0:\n",
    "                            # Activar alarma visual\n",
    "                            cv2.putText(undistorted_frame, 'INTRUSION DETECTED', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                            intrusion_detected = True\n",
    "                            break\n",
    "\n",
    "    # Si se detecta una intrusión, activar el sonido de alarma\n",
    "    if intrusion_detected and not alarm_active:\n",
    "        winsound.Beep(1000, 100)  # Emitir un pitido a 1000 Hz por 100 ms\n",
    "        alarm_active = True\n",
    "    elif not intrusion_detected and alarm_active:\n",
    "        # Desactivar alarma (podrías añadir aquí alguna señal acústica para indicar el final)\n",
    "        alarm_active = False\n",
    "\n",
    "    # Mostrar el video en tiempo real con el área prohibida dibujada\n",
    "    cv2.imshow('Intrusion Detection', undistorted_frame)\n",
    "    \n",
    "    # Restablecer la detección de intrusión para la próxima iteración\n",
    "    intrusion_detected = False\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2.aruco as aruco\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import winsound\n",
    "\n",
    "# Cargar el modelo MobileNet SSD v2 pre-entrenado de TensorFlow Hub\n",
    "MODEL_PATH = \"ssd_mobilenet_v2_model\" # Asegúrate de que esta ruta sea correcta\n",
    "detector = tf.saved_model.load(MODEL_PATH)\n",
    "\n",
    "# Cargar los parámetros de la cámara desde el archivo de calibración\n",
    "calibration_data = np.load('calibration_params.npz')\n",
    "camera_matrix = calibration_data['mtx']\n",
    "dist_coeffs = calibration_data['dist']\n",
    "\n",
    "# Configuración inicial de ArUco\n",
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_50)  # ArUco de 6x6\n",
    "aruco_params = aruco.DetectorParameters_create()\n",
    "\n",
    "# Inicializar la cámara\n",
    "cap = cv2.VideoCapture(0)   # 0 para la cámara web predeterminada\n",
    "\n",
    "# Factor de desplazamiento para ampliar el área alrededor del marcador\n",
    "expand_by = 100\n",
    "\n",
    "# Variable para controlar cada cuántos cuadros procesar\n",
    "process_every_n_frames = 5\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # Solo procesar 1 de cada `process_every_n_frames` cuadros\n",
    "    if frame_count % process_every_n_frames != 0:\n",
    "        continue\n",
    "\n",
    "    # Corregir la distorsión de la imagen\n",
    "    h, w = frame.shape[:2]\n",
    "    new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, dist_coeffs, (w, h), 1, (w, h))\n",
    "    undistorted_frame = cv2.undistort(frame, camera_matrix, dist_coeffs, None, new_camera_matrix)\n",
    "\n",
    "    # Recortar el área útil\n",
    "    x, y, w, h = roi\n",
    "    undistorted_frame = undistorted_frame[y:y+h, x:x+w]\n",
    "\n",
    "    # Detección de marcadores ArUco en la imagen corregida\n",
    "    corners, ids, _ = aruco.detectMarkers(undistorted_frame, aruco_dict, parameters=aruco_params)\n",
    "    \n",
    "    prohibited_area = None\n",
    "    \n",
    "    if ids is not None:\n",
    "        for i in range(len(ids)):\n",
    "            c = corners[i][0]\n",
    "            \n",
    "            # Expande cada esquina del área prohibida alrededor del marcador\n",
    "            top_left = [c[0][0] - expand_by, c[0][1] - expand_by]\n",
    "            top_right = [c[1][0] + expand_by, c[1][1] - expand_by]\n",
    "            bottom_right = [c[2][0] + expand_by, c[2][1] + expand_by]\n",
    "            bottom_left = [c[3][0] - expand_by, c[3][1] + expand_by]\n",
    "            \n",
    "            # Crear el área prohibida ampliada alrededor del marcador en el suelo\n",
    "            prohibited_area = np.array([top_left, top_right, bottom_right, bottom_left], dtype=np.int32)\n",
    "            \n",
    "            # Dibujar el área prohibida en la imagen\n",
    "            cv2.polylines(undistorted_frame, [prohibited_area], isClosed=True, color=(0, 255, 0), thickness=3)\n",
    "\n",
    "    # Preprocesar la imagen para el modelo de detección de personas\n",
    "    input_tensor = tf.convert_to_tensor(undistorted_frame)\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # Realizar la detección\n",
    "    detections = detector(input_tensor)\n",
    "\n",
    "    # Procesar las detecciones\n",
    "    boxes = detections['detection_boxes'][0].numpy()\n",
    "    classes = detections['detection_classes'][0].numpy().astype(np.int32)\n",
    "    scores = detections['detection_scores'][0].numpy()\n",
    "\n",
    "    # Dibujar las detecciones en el frame\n",
    "    height, width, _ = undistorted_frame.shape\n",
    "    intrusion_detected = False\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "        if scores[i] > 0.5 and classes[i] == 1:  # class 1 es 'person'\n",
    "            ymin, xmin, ymax, xmax = boxes[i]\n",
    "            xmin = int(xmin * width)\n",
    "            xmax = int(xmax * width)\n",
    "            ymin = int(ymin * height)\n",
    "            ymax = int(ymax * height)\n",
    "\n",
    "            # Dibujar la caja de detección de persona\n",
    "            cv2.rectangle(undistorted_frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "            cv2.putText(undistorted_frame, f'Person: {scores[i]:.2f}', (xmin, ymin - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            # Verificar si la persona está dentro del área prohibida\n",
    "            if prohibited_area is not None:\n",
    "                for (px, py) in [(xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)]:\n",
    "                    if cv2.pointPolygonTest(prohibited_area, (px, py), False) >= 0:\n",
    "                        intrusion_detected = True\n",
    "                        break\n",
    "\n",
    "    # Si se detecta una intrusión, mostrar alerta y activar sonido\n",
    "    if intrusion_detected:\n",
    "        cv2.putText(undistorted_frame, 'INTRUSION DETECTED', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        winsound.Beep(1000, 100)  # Emitir un pitido a 1000 Hz por 100 ms\n",
    "\n",
    "    # Mostrar el video en tiempo real con el área prohibida y detecciones de personas\n",
    "    cv2.imshow('Intrusion Detection', undistorted_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
